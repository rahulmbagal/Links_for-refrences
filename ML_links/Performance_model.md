# Choosing the Right Metric for Evaluating Machine Learning Models

https://medium.com/usf-msds/choosing-the-right-metric-for-evaluating-machine-learning-models-part-2-86d5649a5428


# metrics for multi class:
https://blog.revolutionanalytics.com/2016/03/com_class_eval_metrics_r.html

# Confusion matrix:
https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/

# ROC curve and precison and recall when to used for imbalanced data:
https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba

https://classeval.wordpress.com/introduction/basic-evaluation-measures/

# why 1-specificity:
https://medium.com/greyatom/lets-learn-about-auc-roc-curve-4a94b4d88152


# micro-average-vs-macro-average-performance
https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin

https://www.youtube.com/watch?v=xugjARegisk

https://www.youtube.com/watch?v=DF-rJA-eOUQ


# Precision and Recall at K method:
https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54
