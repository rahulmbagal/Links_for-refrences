{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        # store the target image width, height, and interpolation\n",
    "        # method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        # resize the image to a fixed size, ignoring the aspect\n",
    "        # ratio\n",
    "        return cv2.resize(image, (self.width, self.height),interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "class ImageToArrayPreprocessor:\n",
    "    def __init__(self, dataFormat=None):\n",
    "        # store the image data format\n",
    "        self.dataFormat = dataFormat\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        # apply the Keras utility function that correctly rearranges\n",
    "        # the dimensions of the image\n",
    "#         return img_to_array(image, data_format=self.dataFormat)\n",
    "        return img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "#     def __init__(self, preprocessors=None):\n",
    "    def __init__(self, width, height):\n",
    "        from tqdm import tqdm\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "\n",
    "\n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "        # initialize the list of features and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for img in tqdm(os.listdir(imagePaths)):\n",
    "            label = img\n",
    "            path = os.path.join(imagePaths,img)\n",
    "            for filename in os.listdir(path):\n",
    "                image = cv2.imread(os.path.join(path, filename))\n",
    "                sp = SimplePreprocessor(self.width, self.height)\n",
    "                image = sp.preprocess(image)\n",
    "#                 print (\"sp completed\")\n",
    "                iap = ImageToArrayPreprocessor()\n",
    "                image = iap.preprocess(image)\n",
    "\n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "        return (np.array(data), np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Shallow_Net:\n",
    "    \n",
    "    def build(width, height, depth, classes):\n",
    "        \n",
    "        model = Sequential()\n",
    "        inputShape = (width, height, depth)\n",
    "        \n",
    "        if K.image_data_format ==\"channel_first\":\n",
    "            inputShape = (depth, width, height)\n",
    "        \n",
    "        model.add(Conv2D(filters = 32, kernel_size = (3,3), padding=\"same\", input_shape = inputShape))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "                  \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = 'G:/pyimagesearch/SB_Code/SB_Code/datasets/animals/'\n",
    "\n",
    "sdl = SimpleDatasetLoader(width = 32, height = 32)\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "print ('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['cats', 'dogs', 'panda'], dtype='<U5'),\n",
       " array([1000, 1000, 1000], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.005)\n",
    "model = Shallow_Net.build(width=32, height=32, depth=3, classes=3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/40\n",
      " - 8s - loss: 1.0965 - acc: 0.3533 - val_loss: 1.0973 - val_acc: 0.3320\n",
      "Epoch 2/40\n",
      " - 8s - loss: 1.0959 - acc: 0.3778 - val_loss: 1.0959 - val_acc: 0.3320\n",
      "Epoch 3/40\n",
      " - 7s - loss: 1.0950 - acc: 0.3916 - val_loss: 1.0957 - val_acc: 0.3200\n",
      "Epoch 4/40\n",
      " - 8s - loss: 1.0941 - acc: 0.4191 - val_loss: 1.0935 - val_acc: 0.3893\n",
      "Epoch 5/40\n",
      " - 8s - loss: 1.0929 - acc: 0.3880 - val_loss: 1.0925 - val_acc: 0.3320\n",
      "Epoch 6/40\n",
      " - 7s - loss: 1.0924 - acc: 0.3773 - val_loss: 1.0921 - val_acc: 0.4147\n",
      "Epoch 7/40\n",
      " - 7s - loss: 1.0914 - acc: 0.4004 - val_loss: 1.0905 - val_acc: 0.4747\n",
      "Epoch 8/40\n",
      " - 7s - loss: 1.0900 - acc: 0.4631 - val_loss: 1.0909 - val_acc: 0.3533\n",
      "Epoch 9/40\n",
      " - 8s - loss: 1.0891 - acc: 0.4587 - val_loss: 1.0881 - val_acc: 0.4067\n",
      "Epoch 10/40\n",
      " - 8s - loss: 1.0881 - acc: 0.4804 - val_loss: 1.0874 - val_acc: 0.4320\n",
      "Epoch 11/40\n",
      " - 9s - loss: 1.0871 - acc: 0.4782 - val_loss: 1.0868 - val_acc: 0.4867\n",
      "Epoch 12/40\n",
      " - 8s - loss: 1.0856 - acc: 0.4538 - val_loss: 1.0860 - val_acc: 0.4307\n",
      "Epoch 13/40\n",
      " - 7s - loss: 1.0843 - acc: 0.4813 - val_loss: 1.0839 - val_acc: 0.4920\n",
      "Epoch 14/40\n",
      " - 7s - loss: 1.0828 - acc: 0.5133 - val_loss: 1.0814 - val_acc: 0.4933\n",
      "Epoch 15/40\n",
      " - 8s - loss: 1.0814 - acc: 0.4738 - val_loss: 1.0803 - val_acc: 0.4120\n",
      "Epoch 16/40\n",
      " - 8s - loss: 1.0794 - acc: 0.4907 - val_loss: 1.0792 - val_acc: 0.4627\n",
      "Epoch 17/40\n",
      " - 8s - loss: 1.0774 - acc: 0.5044 - val_loss: 1.0770 - val_acc: 0.4627\n",
      "Epoch 18/40\n",
      " - 9s - loss: 1.0750 - acc: 0.5147 - val_loss: 1.0753 - val_acc: 0.5027\n",
      "Epoch 19/40\n",
      " - 10s - loss: 1.0728 - acc: 0.5058 - val_loss: 1.0734 - val_acc: 0.4413\n",
      "Epoch 20/40\n",
      " - 9s - loss: 1.0699 - acc: 0.4987 - val_loss: 1.0677 - val_acc: 0.4733\n",
      "Epoch 21/40\n",
      " - 8s - loss: 1.0669 - acc: 0.5027 - val_loss: 1.0656 - val_acc: 0.4400\n",
      "Epoch 22/40\n",
      " - 8s - loss: 1.0635 - acc: 0.5218 - val_loss: 1.0620 - val_acc: 0.5080\n",
      "Epoch 23/40\n",
      " - 8s - loss: 1.0591 - acc: 0.5133 - val_loss: 1.0595 - val_acc: 0.4787\n",
      "Epoch 24/40\n",
      " - 8s - loss: 1.0543 - acc: 0.5191 - val_loss: 1.0529 - val_acc: 0.4920\n",
      "Epoch 25/40\n",
      " - 8s - loss: 1.0486 - acc: 0.5209 - val_loss: 1.0484 - val_acc: 0.4773\n",
      "Epoch 26/40\n",
      " - 8s - loss: 1.0422 - acc: 0.5102 - val_loss: 1.0394 - val_acc: 0.5280\n",
      "Epoch 27/40\n",
      " - 11s - loss: 1.0354 - acc: 0.5338 - val_loss: 1.0330 - val_acc: 0.5080\n",
      "Epoch 28/40\n",
      " - 12s - loss: 1.0265 - acc: 0.5449 - val_loss: 1.0245 - val_acc: 0.4987\n",
      "Epoch 29/40\n",
      " - 13s - loss: 1.0167 - acc: 0.5258 - val_loss: 1.0133 - val_acc: 0.5320\n",
      "Epoch 30/40\n",
      " - 11s - loss: 1.0050 - acc: 0.5462 - val_loss: 1.0034 - val_acc: 0.5107\n",
      "Epoch 31/40\n",
      " - 10s - loss: 0.9934 - acc: 0.5484 - val_loss: 0.9898 - val_acc: 0.5133\n",
      "Epoch 32/40\n",
      " - 11s - loss: 0.9805 - acc: 0.5453 - val_loss: 0.9768 - val_acc: 0.5160\n",
      "Epoch 33/40\n",
      " - 11s - loss: 0.9669 - acc: 0.5422 - val_loss: 0.9655 - val_acc: 0.5227\n",
      "Epoch 34/40\n",
      " - 11s - loss: 0.9536 - acc: 0.5556 - val_loss: 0.9538 - val_acc: 0.5093\n",
      "Epoch 35/40\n",
      " - 11s - loss: 0.9423 - acc: 0.5440 - val_loss: 0.9436 - val_acc: 0.5173\n",
      "Epoch 36/40\n",
      " - 11s - loss: 0.9316 - acc: 0.5547 - val_loss: 0.9363 - val_acc: 0.5293\n",
      "Epoch 37/40\n",
      " - 11s - loss: 0.9228 - acc: 0.5600 - val_loss: 0.9275 - val_acc: 0.5253\n",
      "Epoch 38/40\n",
      " - 11s - loss: 0.9147 - acc: 0.5560 - val_loss: 0.9212 - val_acc: 0.5280\n",
      "Epoch 39/40\n",
      " - 11s - loss: 0.9079 - acc: 0.5507 - val_loss: 0.9167 - val_acc: 0.5040\n",
      "Epoch 40/40\n",
      " - 10s - loss: 0.9029 - acc: 0.5444 - val_loss: 0.9147 - val_acc: 0.5320\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs = 40, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        cat       0.53      0.32      0.40       262\n",
      "        dog       0.45      0.51      0.48       249\n",
      "      panda       0.61      0.79      0.69       239\n",
      "\n",
      "avg / total       0.53      0.53      0.52       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=[\"cat\", \"dog\", \"panda\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
