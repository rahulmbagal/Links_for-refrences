# Loss_function:
https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0

https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html


# L1 and L2 loss:
http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/


# cross entropy:
https://towardsdatascience.com/demystifying-cross-entropy-e80e3ad54a8



# Multi-Class Multi-Label Classification With Neural Networks:
https://www.depends-on-the-definition.com/guide-to-multi-label-classification-with-neural-networks

#  Optimizer functions in neural network:
http://ruder.io/optimizing-gradient-descent/

http://cs231n.github.io/neural-networks-3/


# Momentum:
https://distill.pub/2017/momentum/


# RNN:
http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/

http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/

# LSTM

# CNN Time series:
http://blog.avenuecode.com/using-deep-convolutional-neural-networks-dcnns-for-time-series-forecasting-using-tensorflow-part-1
http://blog.avenuecode.com/using-deep-convolutional-neural-networks-dcnns-for-time-series-forecasting-using-tensorflow-part-2
http://blog.avenuecode.com/using-deep-convolutional-neural-networks-dcnns-for-time-series-forecasting-using-tensorflow-part-3


